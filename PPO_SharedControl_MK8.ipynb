{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Logging to ./ppo_tensorboard/PPO_28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tnlab\\AppData\\Roaming\\Python\\Python312\\site-packages\\stable_baselines3\\common\\policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 778  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 1024 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 782        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 2          |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22062328 |\n",
      "|    clip_fraction        | 0.556      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 295        |\n",
      "|    n_updates            | 4          |\n",
      "|    policy_gradient_loss | 0.164      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 809        |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 788      |\n",
      "|    iterations           | 3        |\n",
      "|    time_elapsed         | 3        |\n",
      "|    total_timesteps      | 3072     |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 8.801878 |\n",
      "|    clip_fraction        | 0.727    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    explained_variance   | 0.621    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 349      |\n",
      "|    n_updates            | 8        |\n",
      "|    policy_gradient_loss | 0.214    |\n",
      "|    std                  | 1        |\n",
      "|    value_loss           | 1.02e+03 |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 790        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.50412357 |\n",
      "|    clip_fraction        | 0.625      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.545      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 485        |\n",
      "|    n_updates            | 12         |\n",
      "|    policy_gradient_loss | 0.158      |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 951        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 793         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027957708 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 462         |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | 0.0189      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1e+03       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 794        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 7          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11512466 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.757      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 365        |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | 0.0212     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 810        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 796          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 7168         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037401235 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 356          |\n",
      "|    n_updates            | 24           |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 733          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004392298 |\n",
      "|    clip_fraction        | 0.0449      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 219         |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | 0.00074     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 482         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 776        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 11         |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01183806 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.872      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 273        |\n",
      "|    n_updates            | 32         |\n",
      "|    policy_gradient_loss | 0.00143    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 573        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 777         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008396316 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | 0.0334      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 630         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 780         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060557388 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | 0.0133      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 527         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 781        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12341814 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.917      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 202        |\n",
      "|    n_updates            | 44         |\n",
      "|    policy_gradient_loss | 0.0265     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 455        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 782         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050970316 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 783          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073932884 |\n",
      "|    clip_fraction        | 0.211        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 175          |\n",
      "|    n_updates            | 52           |\n",
      "|    policy_gradient_loss | 0.00796      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 380          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 783         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044154905 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 388         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 784         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.106105074 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | 0.0282      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 330         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 779         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 22          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016637981 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.000504   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 755       |\n",
      "|    iterations           | 18        |\n",
      "|    time_elapsed         | 24        |\n",
      "|    total_timesteps      | 18432     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0085124 |\n",
      "|    clip_fraction        | 0.127     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    explained_variance   | 0.947     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 97.6      |\n",
      "|    n_updates            | 68        |\n",
      "|    policy_gradient_loss | 0.00249   |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 218       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 756         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015759597 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | 0.00454     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 276         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 756        |\n",
      "|    iterations           | 20         |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11395066 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 128        |\n",
      "|    n_updates            | 76         |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 277        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 757        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 21504      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07357621 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 111        |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | 0.0128     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 230        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 758        |\n",
      "|    iterations           | 22         |\n",
      "|    time_elapsed         | 29         |\n",
      "|    total_timesteps      | 22528      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05881463 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 85.7       |\n",
      "|    n_updates            | 84         |\n",
      "|    policy_gradient_loss | 0.0102     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 186        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 759          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 23552        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0106563065 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 75.7         |\n",
      "|    n_updates            | 88           |\n",
      "|    policy_gradient_loss | 0.00453      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 164          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 758         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022079553 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.9        |\n",
      "|    n_updates            | 92          |\n",
      "|    policy_gradient_loss | 0.00256     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 759        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 33         |\n",
      "|    total_timesteps      | 25600      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42361644 |\n",
      "|    clip_fraction        | 0.51       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 103        |\n",
      "|    n_updates            | 96         |\n",
      "|    policy_gradient_loss | 0.0565     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 213        |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 746       |\n",
      "|    iterations           | 26        |\n",
      "|    time_elapsed         | 35        |\n",
      "|    total_timesteps      | 26624     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0850702 |\n",
      "|    clip_fraction        | 0.531     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    explained_variance   | 0.987     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 75.3      |\n",
      "|    n_updates            | 100       |\n",
      "|    policy_gradient_loss | 0.0517    |\n",
      "|    std                  | 1         |\n",
      "|    value_loss           | 158       |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 748        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 36         |\n",
      "|    total_timesteps      | 27648      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02800769 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 63.6       |\n",
      "|    n_updates            | 104        |\n",
      "|    policy_gradient_loss | 0.0131     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 139        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 749        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 38         |\n",
      "|    total_timesteps      | 28672      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01393445 |\n",
      "|    clip_fraction        | 0.416      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 62.6       |\n",
      "|    n_updates            | 108        |\n",
      "|    policy_gradient_loss | 0.0505     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 129        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 749        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 39         |\n",
      "|    total_timesteps      | 29696      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12650222 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 79         |\n",
      "|    n_updates            | 112        |\n",
      "|    policy_gradient_loss | 0.0357     |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 153        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 751         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058876008 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | 0.0099      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 752         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 31744       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015869271 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 754         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042993974 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | 0.00312     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 755         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 33792       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002020515 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | 0.00074     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 96.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 756          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020965845 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 56.6         |\n",
      "|    n_updates            | 132          |\n",
      "|    policy_gradient_loss | 0.000229     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 118          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 757         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 35840       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002283503 |\n",
      "|    clip_fraction        | 0.00537     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.000379   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 759         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010024539 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.2        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -4.19e-05   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 90.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 760          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 49           |\n",
      "|    total_timesteps      | 37888        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035990137 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 144          |\n",
      "|    policy_gradient_loss | 0.000195     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 81.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 761          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 51           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037351402 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.9         |\n",
      "|    n_updates            | 148          |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 76.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 762         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 39936       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014139386 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.7        |\n",
      "|    n_updates            | 152         |\n",
      "|    policy_gradient_loss | 0.00469     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 763         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 53          |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052906126 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.2        |\n",
      "|    n_updates            | 156         |\n",
      "|    policy_gradient_loss | 0.00211     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 90.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 41984        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005116326 |\n",
      "|    clip_fraction        | 0.0552       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 34.4         |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 74.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 765          |\n",
      "|    iterations           | 42           |\n",
      "|    time_elapsed         | 56           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042489427 |\n",
      "|    clip_fraction        | 0.0203       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 164          |\n",
      "|    policy_gradient_loss | -0.000397    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 68.3         |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 766        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 57         |\n",
      "|    total_timesteps      | 44032      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01105478 |\n",
      "|    clip_fraction        | 0.0435     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 34.1       |\n",
      "|    n_updates            | 168        |\n",
      "|    policy_gradient_loss | -0.000258  |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 71.8       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 767         |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005710178 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 172         |\n",
      "|    policy_gradient_loss | 0.00289     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 69          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 767         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 46080       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003428014 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.3        |\n",
      "|    n_updates            | 176         |\n",
      "|    policy_gradient_loss | -0.000208   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 71.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 768           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 61            |\n",
      "|    total_timesteps      | 47104         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038912165 |\n",
      "|    clip_fraction        | 0.0701        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 0.995         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 28.1          |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.00116      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 61            |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 769          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 62           |\n",
      "|    total_timesteps      | 48128        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051489137 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28           |\n",
      "|    n_updates            | 184          |\n",
      "|    policy_gradient_loss | -0.000194    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 57.7         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 769          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 63           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031941077 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.5         |\n",
      "|    n_updates            | 188          |\n",
      "|    policy_gradient_loss | -0.000431    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 60.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 769         |\n",
      "|    iterations           | 49          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 50176       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010404533 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | 0.00109     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 56.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 769         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 51200       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011441413 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | 0.00567     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 58.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 769        |\n",
      "|    iterations           | 51         |\n",
      "|    time_elapsed         | 67         |\n",
      "|    total_timesteps      | 52224      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01982383 |\n",
      "|    clip_fraction        | 0.0874     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.4       |\n",
      "|    n_updates            | 200        |\n",
      "|    policy_gradient_loss | 0.00179    |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 51.7       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 769         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029615495 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | 0.0189      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 49.4        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 770           |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 70            |\n",
      "|    total_timesteps      | 54272         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037606969 |\n",
      "|    clip_fraction        | 0.123         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 0.996         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 24.1          |\n",
      "|    n_updates            | 208           |\n",
      "|    policy_gradient_loss | -0.00197      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 52.1          |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 771         |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007827551 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 212         |\n",
      "|    policy_gradient_loss | -0.000276   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 46.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 772         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 56320       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004407219 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.000195   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 50.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 772         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 74          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014698956 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 220         |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 45          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 773         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 58368       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020420171 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 224         |\n",
      "|    policy_gradient_loss | 0.00631     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 43.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 774         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018839743 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | 0.00533     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 46.9        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 774          |\n",
      "|    iterations           | 59           |\n",
      "|    time_elapsed         | 77           |\n",
      "|    total_timesteps      | 60416        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021263827 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 232          |\n",
      "|    policy_gradient_loss | 0.000453     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 39.8         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 775          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 79           |\n",
      "|    total_timesteps      | 61440        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076328665 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 21           |\n",
      "|    n_updates            | 236          |\n",
      "|    policy_gradient_loss | 0.00152      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 44.3         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 774         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 80          |\n",
      "|    total_timesteps      | 62464       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008102392 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | 0.000752    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 40.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015375573 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 244         |\n",
      "|    policy_gradient_loss | 0.00297     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 40.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 775         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 64512       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004403513 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.5        |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.000879   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 44.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 84          |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001024384 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 252         |\n",
      "|    policy_gradient_loss | 0.000271    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 776         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 85          |\n",
      "|    total_timesteps      | 66560       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002620728 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | 0.000189    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 41.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 777         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007827191 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.5        |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 38          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 777          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 88           |\n",
      "|    total_timesteps      | 68608        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017837805 |\n",
      "|    clip_fraction        | 0.0635       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.1         |\n",
      "|    n_updates            | 264          |\n",
      "|    policy_gradient_loss | -0.000535    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 39.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 778          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 89           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013744205 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 20.9         |\n",
      "|    n_updates            | 268          |\n",
      "|    policy_gradient_loss | 1.19e-05     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 43.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 778          |\n",
      "|    iterations           | 69           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 70656        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013817473 |\n",
      "|    clip_fraction        | 0.185        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.9         |\n",
      "|    n_updates            | 272          |\n",
      "|    policy_gradient_loss | -8.62e-05    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 29           |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 779          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 71680        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033475705 |\n",
      "|    clip_fraction        | 0.00903      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19.1         |\n",
      "|    n_updates            | 276          |\n",
      "|    policy_gradient_loss | -0.00122     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 37.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 779         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 72704       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002206378 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 780         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016827092 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 284         |\n",
      "|    policy_gradient_loss | 0.00624     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 37.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 780         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 95          |\n",
      "|    total_timesteps      | 74752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009998536 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 42.2        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 780          |\n",
      "|    iterations           | 74           |\n",
      "|    time_elapsed         | 97           |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027108598 |\n",
      "|    clip_fraction        | 0.072        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 13.2         |\n",
      "|    n_updates            | 292          |\n",
      "|    policy_gradient_loss | 0.00174      |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 28.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 781          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 98           |\n",
      "|    total_timesteps      | 76800        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012495213 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 17.4         |\n",
      "|    n_updates            | 296          |\n",
      "|    policy_gradient_loss | 9.12e-06     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 35.5         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 781         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 99          |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003401391 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 32.8        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 781          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 100          |\n",
      "|    total_timesteps      | 78848        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025421141 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 304          |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 36.4         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 782         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 102         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010211429 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 308         |\n",
      "|    policy_gradient_loss | -0.000328   |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 35.1        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 782          |\n",
      "|    iterations           | 79           |\n",
      "|    time_elapsed         | 103          |\n",
      "|    total_timesteps      | 80896        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044134604 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 11.5         |\n",
      "|    n_updates            | 312          |\n",
      "|    policy_gradient_loss | -0.000477    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 24.2         |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 782           |\n",
      "|    iterations           | 80            |\n",
      "|    time_elapsed         | 104           |\n",
      "|    total_timesteps      | 81920         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045645534 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.42         |\n",
      "|    explained_variance   | 0.997         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 16.6          |\n",
      "|    n_updates            | 316           |\n",
      "|    policy_gradient_loss | -0.00033      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 33.6          |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 783          |\n",
      "|    iterations           | 81           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 82944        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058108503 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16           |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.000217    |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 32.2         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 783         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 107         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019434012 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 324         |\n",
      "|    policy_gradient_loss | 0.00012     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 35.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 784         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 108         |\n",
      "|    total_timesteps      | 84992       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012219097 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | 0.00158     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 33.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 784          |\n",
      "|    iterations           | 84           |\n",
      "|    time_elapsed         | 109          |\n",
      "|    total_timesteps      | 86016        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043239444 |\n",
      "|    clip_fraction        | 0.0911       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.8         |\n",
      "|    n_updates            | 332          |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 22           |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 784         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 110         |\n",
      "|    total_timesteps      | 87040       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004469566 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 32.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 784          |\n",
      "|    iterations           | 86           |\n",
      "|    time_elapsed         | 112          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036166029 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.7         |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 785          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 89088        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070218816 |\n",
      "|    clip_fraction        | 0.0757       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.3         |\n",
      "|    n_updates            | 344          |\n",
      "|    policy_gradient_loss | 0.000597     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 34.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 785          |\n",
      "|    iterations           | 88           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 90112        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048494213 |\n",
      "|    clip_fraction        | 0.0676       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.4         |\n",
      "|    n_updates            | 348          |\n",
      "|    policy_gradient_loss | -0.000211    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 32.4         |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 785       |\n",
      "|    iterations           | 89        |\n",
      "|    time_elapsed         | 115       |\n",
      "|    total_timesteps      | 91136     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0109176 |\n",
      "|    clip_fraction        | 0.111     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    explained_variance   | 0.997     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 10.6      |\n",
      "|    n_updates            | 352       |\n",
      "|    policy_gradient_loss | 0.00325   |\n",
      "|    std                  | 1.01      |\n",
      "|    value_loss           | 21.2      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 117         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029569961 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.6        |\n",
      "|    n_updates            | 356         |\n",
      "|    policy_gradient_loss | 0.0053      |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 93184       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004497675 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.000616   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 31.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 786         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 119         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012239156 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 364         |\n",
      "|    policy_gradient_loss | 0.00398     |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 31.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 787        |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 120        |\n",
      "|    total_timesteps      | 95232      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03177926 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.7       |\n",
      "|    n_updates            | 368        |\n",
      "|    policy_gradient_loss | 0.00271    |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 31.6       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 787          |\n",
      "|    iterations           | 94           |\n",
      "|    time_elapsed         | 122          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049002855 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 10.6         |\n",
      "|    n_updates            | 372          |\n",
      "|    policy_gradient_loss | 0.000761     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 20.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 787          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 123          |\n",
      "|    total_timesteps      | 97280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010730259 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 16.5         |\n",
      "|    n_updates            | 376          |\n",
      "|    policy_gradient_loss | 0.00227      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 30.9         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 788         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005638741 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 788         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 126         |\n",
      "|    total_timesteps      | 99328       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010683065 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.2        |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 28.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 788         |\n",
      "|    iterations           | 98          |\n",
      "|    time_elapsed         | 127         |\n",
      "|    total_timesteps      | 100352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013905518 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.000448   |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 31.2        |\n",
      "-----------------------------------------\n",
      "Model saved to trained_models\\gamma_ppo_model.zip\n",
      "Metrics saved to 'training_metrics/'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# For rendering (optional):\n",
    "try:\n",
    "    import pygame\n",
    "except ImportError:\n",
    "    pygame = None\n",
    "\n",
    "###############################################################################\n",
    "# CONSTANTS & UTILS\n",
    "###############################################################################\n",
    "FULL_VIEW_SIZE = (1200, 800)\n",
    "SCALING_FACTOR_X = FULL_VIEW_SIZE[0] / 600.0\n",
    "SCALING_FACTOR_Y = FULL_VIEW_SIZE[1] / 600.0\n",
    "SCALING_FACTOR   = (SCALING_FACTOR_X + SCALING_FACTOR_Y) / 2\n",
    "\n",
    "DOT_RADIUS       = int(15 * SCALING_FACTOR)\n",
    "TARGET_RADIUS    = int(10 * SCALING_FACTOR)\n",
    "OBSTACLE_RADIUS  = int(10 * SCALING_FACTOR)\n",
    "COLLISION_BUFFER = int(5  * SCALING_FACTOR)\n",
    "MAX_SPEED        = 3 * SCALING_FACTOR\n",
    "NOISE_MAGNITUDE  = 0.5\n",
    "RENDER_FPS       = 30\n",
    "\n",
    "START_POS = np.array([FULL_VIEW_SIZE[0]//2, FULL_VIEW_SIZE[1]//2], dtype=np.float32)\n",
    "\n",
    "WHITE = (255, 255, 255)\n",
    "GRAY  = (128, 128, 128)\n",
    "YELLOW= (255, 255, 0)\n",
    "BLACK = (0, 0, 0)\n",
    "\n",
    "def distance(a, b):\n",
    "    return math.hypot(a[0] - b[0], a[1] - b[1])\n",
    "\n",
    "def check_line_collision(start, end, center, radius):\n",
    "    dx = end[0] - start[0]\n",
    "    dy = end[1] - start[1]\n",
    "    fx = center[0] - start[0]\n",
    "    fy = center[1] - start[1]\n",
    "    l2 = dx*dx + dy*dy\n",
    "    if l2 < 1e-9:\n",
    "        return distance(start, center) <= radius\n",
    "    t = max(0, min(1, (fx*dx + fy*dy) / l2))\n",
    "    px = start[0] + t*dx\n",
    "    py = start[1] + t*dy\n",
    "    return distance((px, py), center) <= radius\n",
    "\n",
    "def line_collision(pos, new_pos, obstacles):\n",
    "    for obs in obstacles:\n",
    "        if check_line_collision(pos, new_pos, obs, OBSTACLE_RADIUS + COLLISION_BUFFER):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def inside_obstacle(pos, obstacles):\n",
    "    for obs in obstacles:\n",
    "        if distance(pos, obs) <= (OBSTACLE_RADIUS + DOT_RADIUS):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def potential_field_dir(pos, goal, obstacles):\n",
    "    \"\"\"\n",
    "    Returns a normalized direction from pos to goal,\n",
    "    plus repulsion from obstacles.\n",
    "    \"\"\"\n",
    "    gx = goal[0] - pos[0]\n",
    "    gy = goal[1] - pos[1]\n",
    "    dg = math.hypot(gx, gy)\n",
    "    if dg < 1e-6:\n",
    "        return np.zeros(2, dtype=np.float32)\n",
    "    att = np.array([gx / dg, gy / dg], dtype=np.float32)\n",
    "\n",
    "    repulse_x = 0.0\n",
    "    repulse_y = 0.0\n",
    "    # Example values; adjusted for a smaller radius\n",
    "    repulsion_radius = 23.0 * SCALING_FACTOR\n",
    "    repulsion_gain   = 30000.0\n",
    "\n",
    "    for obs in obstacles:\n",
    "        dx = pos[0] - obs[0]\n",
    "        dy = pos[1] - obs[1]\n",
    "        dobs = math.hypot(dx, dy)\n",
    "        if dobs < 1e-9:\n",
    "            continue\n",
    "        if dobs < repulsion_radius:\n",
    "            pushx    = dx / dobs\n",
    "            pushy    = dy / dobs\n",
    "            strength = repulsion_gain / (dobs**2)\n",
    "            repulse_x += pushx * strength\n",
    "            repulse_y += pushy * strength\n",
    "\n",
    "    px = att[0] + repulse_x\n",
    "    py = att[1] + repulse_y\n",
    "    mg = math.hypot(px, py)\n",
    "    if mg < 1e-9:\n",
    "        return np.zeros(2, dtype=np.float32)\n",
    "    return np.array([px / mg, py / mg], dtype=np.float32)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# METRICS CALLBACK\n",
    "###############################################################################\n",
    "class MetricsCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    Logs training metrics, records collisions/timeouts, etc.\n",
    "    Also saves plots after training is finished:\n",
    "      - Episode reward\n",
    "      - Average gamma per episode\n",
    "      - Gamma std (exploration measure)\n",
    "      - Critic loss (value loss)\n",
    "      - Actor loss (policy gradient loss)\n",
    "      - Total loss\n",
    "      - Entropy\n",
    "      - Episode length\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.episode_rewards   = []\n",
    "        self.episode_lengths   = []\n",
    "        self.episode_mean_gammas = []\n",
    "        self.episode_std_gammas  = []\n",
    "\n",
    "        self.total_reward = 0.0\n",
    "        self.ep_length    = 0\n",
    "        self.current_episode_gammas = []  # store gamma each step in the current episode\n",
    "        self.n_collisions = 0\n",
    "        self.n_episodes   = 0\n",
    "        \n",
    "        # Loss tracking:\n",
    "        self.losses         = []  # total model loss\n",
    "        self.value_losses   = []  # critic loss\n",
    "        self.policy_losses  = []  # actor (policy) loss\n",
    "        self.entropy_losses = []\n",
    "        self.training_steps = []\n",
    "        self.n_updates      = 0\n",
    "\n",
    "    def _on_training_start(self):\n",
    "        self.episode_rewards.clear()\n",
    "        self.episode_lengths.clear()\n",
    "        self.episode_mean_gammas.clear()\n",
    "        self.episode_std_gammas.clear()\n",
    "\n",
    "        self.total_reward = 0.0\n",
    "        self.ep_length    = 0\n",
    "        self.n_collisions = 0\n",
    "        self.n_episodes   = 0\n",
    "        self.current_episode_gammas.clear()\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        actions = self.locals['actions']\n",
    "        rewards = self.locals['rewards']\n",
    "        dones   = self.locals['dones']\n",
    "        infos   = self.locals['infos']\n",
    "        \n",
    "        # Track step-wise gamma (from the action)\n",
    "        # PPO is vectorized, so for a single env, actions[0] is our scalar\n",
    "        gamma_val = 0.5 * (actions[0] + 1.0)  # map [-1,1] -> [0,1]\n",
    "        self.current_episode_gammas.append(gamma_val)\n",
    "\n",
    "        # Accumulate rewards & steps\n",
    "        r = float(rewards[0])\n",
    "        self.total_reward += r\n",
    "        self.ep_length    += 1\n",
    "\n",
    "        if dones[0]:\n",
    "            # Episode finished\n",
    "            self.episode_rewards.append(self.total_reward)\n",
    "            self.episode_lengths.append(self.ep_length)\n",
    "\n",
    "            # Average & std gamma\n",
    "            mean_gamma = np.mean(self.current_episode_gammas)\n",
    "            std_gamma  = np.std(self.current_episode_gammas)\n",
    "            self.episode_mean_gammas.append(mean_gamma)\n",
    "            self.episode_std_gammas.append(std_gamma)\n",
    "\n",
    "            self.total_reward = 0.0\n",
    "            self.ep_length    = 0\n",
    "            self.current_episode_gammas.clear()\n",
    "            self.n_episodes  += 1\n",
    "\n",
    "            # Collision check\n",
    "            if 'terminal_reason' in infos[0] and infos[0]['terminal_reason'] == 'collision':\n",
    "                self.n_collisions += 1\n",
    "\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_end(self):\n",
    "        \"\"\"\n",
    "        Called when a rollout ends (i.e. after n_steps or n_rollout_steps in PPO).\n",
    "        We can access training logs (losses, etc.) from self.model.logger.name_to_value.\n",
    "        \"\"\"\n",
    "        self.n_updates += 1\n",
    "        logs = self.model.logger.name_to_value or {}\n",
    "        \n",
    "        # Total model loss\n",
    "        if \"train/loss\" in logs:\n",
    "            self.losses.append(logs[\"train/loss\"])\n",
    "            self.training_steps.append(self.n_updates)\n",
    "\n",
    "        # Critic (value) loss\n",
    "        if \"train/value_loss\" in logs:\n",
    "            self.value_losses.append(logs[\"train/value_loss\"])\n",
    "\n",
    "        # Actor (policy) loss\n",
    "        if \"train/policy_gradient_loss\" in logs:\n",
    "            self.policy_losses.append(logs[\"train/policy_gradient_loss\"])\n",
    "\n",
    "        # Entropy\n",
    "        if \"train/entropy_loss\" in logs:\n",
    "            self.entropy_losses.append(logs[\"train/entropy_loss\"])\n",
    "\n",
    "    def _moving_average(self, data, window=10):\n",
    "        if len(data) < window:\n",
    "            return np.array(data)\n",
    "        return np.convolve(data, np.ones(window)/window, mode='valid')\n",
    "\n",
    "    def save_metrics(self, save_dir=\"training_metrics\"):\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # 1) Episode Rewards\n",
    "        if self.episode_rewards:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.episode_rewards, label=\"Episode Reward\", alpha=0.6)\n",
    "            ma_rewards = self._moving_average(self.episode_rewards, 10)\n",
    "            if len(ma_rewards):\n",
    "                plt.plot(range(10 - 1, 10 - 1 + len(ma_rewards)), \n",
    "                         ma_rewards, label=\"MA(10)\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Episode\")\n",
    "            plt.ylabel(\"Reward\")\n",
    "            plt.title(\"Episode Rewards\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, \"episode_rewards.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # 2) Average Gamma per Episode\n",
    "        if self.episode_mean_gammas:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.episode_mean_gammas, label=\"Mean Gamma\", alpha=0.6)\n",
    "            ma_gamma = self._moving_average(self.episode_mean_gammas, 10)\n",
    "            if len(ma_gamma):\n",
    "                plt.plot(range(10 - 1, 10 - 1 + len(ma_gamma)),\n",
    "                         ma_gamma, label=\"MA(10)\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Episode\")\n",
    "            plt.ylabel(\"Gamma (avg)\")\n",
    "            plt.title(\"Average Gamma per Episode\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, \"average_gamma.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # 3) Gamma Std per Episode (Exploration Metric)\n",
    "        if self.episode_std_gammas:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.episode_std_gammas, label=\"Gamma Std\", alpha=0.6)\n",
    "            ma_gstd = self._moving_average(self.episode_std_gammas, 10)\n",
    "            if len(ma_gstd):\n",
    "                plt.plot(range(10 - 1, 10 - 1 + len(ma_gstd)),\n",
    "                         ma_gstd, label=\"MA(10)\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Episode\")\n",
    "            plt.ylabel(\"Std of Gamma\")\n",
    "            plt.title(\"Gamma Std per Episode (Exploration)\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, \"gamma_std.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # 4) Episode Length\n",
    "        if self.episode_lengths:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.episode_lengths, label=\"Episode Length\", alpha=0.6)\n",
    "            ma_length = self._moving_average(self.episode_lengths, 10)\n",
    "            if len(ma_length):\n",
    "                plt.plot(range(10 - 1, 10 - 1 + len(ma_length)),\n",
    "                         ma_length, label=\"MA(10)\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Episode\")\n",
    "            plt.ylabel(\"Length (# steps)\")\n",
    "            plt.title(\"Episode Lengths\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, \"episode_length.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # 5) Total Model Loss\n",
    "        if self.losses:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.training_steps, self.losses, label=\"Total Model Loss\", alpha=0.7)\n",
    "            if len(self.losses) >= 10:\n",
    "                ma_loss = self._moving_average(self.losses, 10)\n",
    "                # Align moving-average x-axis with original\n",
    "                plt.plot(range(self.training_steps[0] + (10 - 1),\n",
    "                               self.training_steps[0] + (10 - 1) + len(ma_loss)),\n",
    "                         ma_loss, label=\"MA(10)\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Training Updates\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(\"Total Model Loss Over Rollouts\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, \"loss.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # 6) Value (Critic) Loss\n",
    "        if self.value_losses:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.value_losses, label=\"Value Loss\", alpha=0.7)\n",
    "            if len(self.value_losses) >= 10:\n",
    "                ma_val_loss = self._moving_average(self.value_losses, 10)\n",
    "                plt.plot(range(10 - 1, 10 - 1 + len(ma_val_loss)), \n",
    "                         ma_val_loss, label=\"MA(10)\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Rollout End #\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(\"Value (Critic) Loss\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, \"value_loss.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # 7) Policy (Actor) Loss\n",
    "        if self.policy_losses:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.policy_losses, label=\"Policy Loss\", alpha=0.7)\n",
    "            if len(self.policy_losses) >= 10:\n",
    "                ma_pol_loss = self._moving_average(self.policy_losses, 10)\n",
    "                plt.plot(range(10 - 1, 10 - 1 + len(ma_pol_loss)), \n",
    "                         ma_pol_loss, label=\"MA(10)\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Rollout End #\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(\"Policy (Actor) Loss\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, \"policy_loss.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # 8) Entropy Loss\n",
    "        if self.entropy_losses:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(self.entropy_losses, label=\"Entropy Loss\", alpha=0.7)\n",
    "            if len(self.entropy_losses) >= 10:\n",
    "                ma_ent_loss = self._moving_average(self.entropy_losses, 10)\n",
    "                plt.plot(range(10 - 1, 10 - 1 + len(ma_ent_loss)), \n",
    "                         ma_ent_loss, label=\"MA(10)\", color='red', linewidth=2)\n",
    "            plt.xlabel(\"Rollout End #\")\n",
    "            plt.ylabel(\"Entropy\")\n",
    "            plt.title(\"Entropy Loss (Exploration Indicator)\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.savefig(os.path.join(save_dir, \"entropy_loss.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        # Write a summary text\n",
    "        with open(os.path.join(save_dir, \"summary.txt\"), \"w\") as f:\n",
    "            f.write(f\"Total Episodes: {len(self.episode_rewards)}\\n\")\n",
    "            if self.episode_rewards:\n",
    "                avg_reward = np.mean(self.episode_rewards)\n",
    "                f.write(f\"Mean Episode Reward: {avg_reward:.3f}\\n\")\n",
    "            f.write(f\"Collisions Count: {self.n_collisions}\\n\")\n",
    "            if self.episode_mean_gammas:\n",
    "                mean_gamma_all = np.mean(self.episode_mean_gammas)\n",
    "                f.write(f\"Mean of Average-Gamma: {mean_gamma_all:.3f}\\n\")\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# A SIMPLE RENDER CALLBACK (OPTIONAL) FOR LIVE VIEW\n",
    "###############################################################################\n",
    "class RenderCallback(BaseCallback):\n",
    "    \"\"\"\n",
    "    A callback that calls env.render() every `render_freq` steps.\n",
    "    This ensures PyGame events get handled so the window does not stay black.\n",
    "    \"\"\"\n",
    "    def __init__(self, render_freq=1, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.render_freq = render_freq\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.render_freq == 0:\n",
    "            self.model.env.envs[0].render()\n",
    "        return True\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# DEMO ARBITRATION ENV\n",
    "###############################################################################\n",
    "class DemoArbitrationEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    The agent controls gamma (in [0,1]) while we simulate a \"perfect direction\"\n",
    "    plus a noisy \"human direction.\" Reward shaping encourages high gamma\n",
    "    near obstacles or goals. Environment cycles among fixed seeds and random seeds\n",
    "    to encourage generalization.\n",
    "    \"\"\"\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": RENDER_FPS}\n",
    "\n",
    "    def __init__(self, visualize=False):\n",
    "        super().__init__()\n",
    "        self.visualize = visualize\n",
    "\n",
    "        # Observation = [dot_x, dot_y, h_dir_x, h_dir_y, goal_x, goal_y, w_dir_x, w_dir_y, dist_ratio]\n",
    "        low  = np.array([0, 0, -1, -1, 0, 0, -1, -1, 0], dtype=np.float32)\n",
    "        high = np.array([\n",
    "            FULL_VIEW_SIZE[0], FULL_VIEW_SIZE[1],\n",
    "            1, 1,\n",
    "            FULL_VIEW_SIZE[0], FULL_VIEW_SIZE[1],\n",
    "            1, 1,\n",
    "            1\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        self.observation_space = spaces.Box(low=low, high=high, shape=(9,), dtype=np.float32)\n",
    "        self.action_space = spaces.Box(low=-1.0, high=1.0, shape=(), dtype=np.float32)\n",
    "\n",
    "        self.dot_pos = None\n",
    "        self.goal_pos = None\n",
    "        self.obstacles = []\n",
    "        self.goals = []\n",
    "\n",
    "        self.step_count = 0\n",
    "        self.max_steps = 300\n",
    "        self.episode_reward = 0.0\n",
    "        self.max_dist = math.hypot(FULL_VIEW_SIZE[0], FULL_VIEW_SIZE[1])\n",
    "\n",
    "        # Reward-shaping parameters\n",
    "        self.alpha = 3.0\n",
    "        self.beta  = 3.0\n",
    "\n",
    "        # Distances where we want higher gamma\n",
    "        self.goal_threshold = 100.0\n",
    "        self.obs_threshold  = 100.0\n",
    "\n",
    "        # Seeds of interest\n",
    "        self.SCENARIO_SEEDS = [0, 1, 2, 58, 487]\n",
    "        self.scenario_index = 0\n",
    "        self.episode_counter = 0\n",
    "\n",
    "        # Probability of picking an unseen random seed\n",
    "        self.random_seed_probability = 0.3\n",
    "\n",
    "        if self.visualize and pygame is not None:\n",
    "            pygame.init()\n",
    "            self.window = pygame.display.set_mode(FULL_VIEW_SIZE)\n",
    "            pygame.display.set_caption(\"Demo Arbitration Environment\")\n",
    "            self.clock = pygame.time.Clock()\n",
    "        else:\n",
    "            self.window = None\n",
    "            self.clock = None\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.episode_counter += 1\n",
    "\n",
    "        # Decide which scenario seed to use\n",
    "        use_random = (random.random() < self.random_seed_probability)\n",
    "        if use_random:\n",
    "            scenario_seed = random.randint(0, 9999999)\n",
    "        else:\n",
    "            scenario_seed = self.SCENARIO_SEEDS[self.scenario_index]\n",
    "            self.scenario_index = (self.scenario_index + 1) % len(self.SCENARIO_SEEDS)\n",
    "\n",
    "        self.randomize_env(scenario_seed)\n",
    "\n",
    "        self.step_count = 0\n",
    "        self.episode_reward = 0.0\n",
    "        self.dot_pos = START_POS.copy()\n",
    "\n",
    "        if self.goals:\n",
    "            idx = random.randint(0, len(self.goals) - 1)\n",
    "            self.goal_pos = self.goals[idx].copy()\n",
    "        else:\n",
    "            # fallback random goal\n",
    "            self.goal_pos = np.array([\n",
    "                random.uniform(0.2*FULL_VIEW_SIZE[0], 0.8*FULL_VIEW_SIZE[0]),\n",
    "                random.uniform(0.2*FULL_VIEW_SIZE[1], 0.8*FULL_VIEW_SIZE[1])\n",
    "            ], dtype=np.float32)\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def randomize_env(self, scenario_seed):\n",
    "        random.seed(scenario_seed)\n",
    "        np.random.seed(scenario_seed)\n",
    "\n",
    "        margin = 50 * SCALING_FACTOR\n",
    "        N_GOALS = 8\n",
    "        N_OBSTACLES = 5\n",
    "        min_goal_distance = 300 * SCALING_FACTOR\n",
    "\n",
    "        new_goals = []\n",
    "        attempts = 0\n",
    "        while len(new_goals) < N_GOALS and attempts < 2000:\n",
    "            x = random.uniform(margin, FULL_VIEW_SIZE[0] - margin)\n",
    "            y = random.uniform(margin, FULL_VIEW_SIZE[1] - margin)\n",
    "            candidate = np.array([x, y], dtype=np.float32)\n",
    "            # Ensure goal is some distance from start\n",
    "            if distance(candidate, START_POS) >= min_goal_distance:\n",
    "                new_goals.append(candidate)\n",
    "            attempts += 1\n",
    "\n",
    "        self.goals = new_goals[:N_GOALS]\n",
    "\n",
    "        # Build obstacles\n",
    "        new_obstacles = []\n",
    "        if len(self.goals) > 1:\n",
    "            obstacle_goals = random.sample(self.goals, k=min(min(N_GOALS-1, N_OBSTACLES), len(self.goals)-1))\n",
    "        else:\n",
    "            obstacle_goals = self.goals\n",
    "\n",
    "        for goal in obstacle_goals:\n",
    "            t = random.uniform(0.6, 0.8)\n",
    "            base_point = START_POS + t*(goal - START_POS)\n",
    "            vec = goal - START_POS\n",
    "            vec_norm = np.linalg.norm(vec)\n",
    "            if vec_norm < 1e-6:\n",
    "                perp = np.array([0, 0], dtype=np.float32)\n",
    "            else:\n",
    "                perp = np.array([-vec[1], vec[0]], dtype=np.float32)\n",
    "                perp /= np.linalg.norm(perp)\n",
    "\n",
    "            offset_mag = random.uniform(20*SCALING_FACTOR, 40*SCALING_FACTOR)\n",
    "            offset = perp * offset_mag * random.choice([-1, 1])\n",
    "            candidate = base_point + offset\n",
    "            candidate[0] = np.clip(candidate[0], margin, FULL_VIEW_SIZE[0] - margin)\n",
    "            candidate[1] = np.clip(candidate[1], margin, FULL_VIEW_SIZE[1] - margin)\n",
    "\n",
    "            valid = True\n",
    "            if distance(candidate, START_POS) < (DOT_RADIUS + OBSTACLE_RADIUS + 10):\n",
    "                valid = False\n",
    "            if distance(candidate, goal) < (TARGET_RADIUS + OBSTACLE_RADIUS + 20):\n",
    "                valid = False\n",
    "            for obs in new_obstacles:\n",
    "                if distance(candidate, obs) < (2*OBSTACLE_RADIUS + 10):\n",
    "                    valid = False\n",
    "            if valid:\n",
    "                new_obstacles.append(candidate)\n",
    "\n",
    "        self.obstacles = new_obstacles\n",
    "\n",
    "    def step(self, action):\n",
    "        raw_a = float(action)\n",
    "        raw_a = np.clip(raw_a, -1.0, 1.0)\n",
    "        gamma_val = 0.5 * (raw_a + 1.0)  # map [-1,1] -> [0,1]\n",
    "\n",
    "        self.step_count += 1\n",
    "\n",
    "        # Potential-field-based \"world\" direction\n",
    "        w_dir = potential_field_dir(self.dot_pos, self.goal_pos, self.obstacles)\n",
    "        # \"Human\" direction is w_dir + noise\n",
    "        noise = np.random.normal(0, NOISE_MAGNITUDE, size=2)\n",
    "        h_dir = w_dir + noise\n",
    "        hm = np.hypot(h_dir[0], h_dir[1])\n",
    "        if hm > 1e-6:\n",
    "            h_dir /= hm\n",
    "\n",
    "        # Combine directions\n",
    "        c_dir = gamma_val * w_dir + (1 - gamma_val) * h_dir\n",
    "        cm = np.hypot(c_dir[0], c_dir[1])\n",
    "        if cm > 1e-6:\n",
    "            c_dir /= cm\n",
    "\n",
    "        move_vec = c_dir * MAX_SPEED\n",
    "        new_pos = self.dot_pos + move_vec\n",
    "\n",
    "        # Collision check\n",
    "        if not line_collision(self.dot_pos, new_pos, self.obstacles):\n",
    "            new_pos[0] = np.clip(new_pos[0], 0, FULL_VIEW_SIZE[0])\n",
    "            new_pos[1] = np.clip(new_pos[1], 0, FULL_VIEW_SIZE[1])\n",
    "            self.dot_pos = new_pos\n",
    "\n",
    "        collided = inside_obstacle(self.dot_pos, self.obstacles)\n",
    "        info = {}\n",
    "        if collided:\n",
    "            original_reward = -2.0\n",
    "            done = True\n",
    "            info[\"terminal_reason\"] = \"collision\"\n",
    "        else:\n",
    "            original_reward = 0.0\n",
    "            done = False\n",
    "            info[\"terminal_reason\"] = None\n",
    "\n",
    "        truncated = (self.step_count >= self.max_steps)\n",
    "        if truncated and not done:\n",
    "            info[\"terminal_reason\"] = \"timeout\"\n",
    "\n",
    "        # Reward shaping\n",
    "        d_goal = distance(self.dot_pos, self.goal_pos)\n",
    "        if self.obstacles:\n",
    "            d_obs = min(distance(self.dot_pos, obs) for obs in self.obstacles)\n",
    "        else:\n",
    "            d_obs = 999999.0\n",
    "\n",
    "        if (d_goal < self.goal_threshold) or (d_obs < self.obs_threshold):\n",
    "            shaping_reward = self.alpha * gamma_val\n",
    "        else:\n",
    "            shaping_reward = -self.beta * gamma_val\n",
    "\n",
    "        reward = original_reward + shaping_reward\n",
    "        self.episode_reward += reward\n",
    "\n",
    "        obs = self._get_obs()\n",
    "        return obs, float(reward), done, truncated, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        to_g = self.goal_pos - self.dot_pos\n",
    "        d = np.hypot(to_g[0], to_g[1])\n",
    "        dist_ratio = d / self.max_dist if self.max_dist > 1e-6 else 0.0\n",
    "\n",
    "        w_dir = potential_field_dir(self.dot_pos, self.goal_pos, self.obstacles)\n",
    "        # For the observation, \"human\" direction is w_dir + noise\n",
    "        noise = np.random.normal(0, NOISE_MAGNITUDE, size=2)\n",
    "        h_dir = w_dir + noise\n",
    "        hm = np.hypot(h_dir[0], h_dir[1])\n",
    "        if hm > 1e-6:\n",
    "            h_dir /= hm\n",
    "\n",
    "        obs = np.concatenate([\n",
    "            self.dot_pos,\n",
    "            h_dir,\n",
    "            self.goal_pos,\n",
    "            w_dir,\n",
    "            [dist_ratio]\n",
    "        ]).astype(np.float32)\n",
    "        return obs\n",
    "\n",
    "    def render(self):\n",
    "        if not self.visualize or (pygame is None):\n",
    "            return\n",
    "\n",
    "        # Handle events so the window is responsive\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                return\n",
    "\n",
    "        self.window.fill(WHITE)\n",
    "        for obs in self.obstacles:\n",
    "            pygame.draw.circle(self.window, GRAY, (int(obs[0]), int(obs[1])), OBSTACLE_RADIUS)\n",
    "        for gpos in self.goals:\n",
    "            pygame.draw.circle(self.window, YELLOW, (int(gpos[0]), int(gpos[1])), TARGET_RADIUS)\n",
    "        pygame.draw.circle(self.window, BLACK, (int(self.goal_pos[0]), int(self.goal_pos[1])),\n",
    "                           TARGET_RADIUS+2, width=2)\n",
    "        pygame.draw.circle(self.window, BLACK, (int(self.dot_pos[0]), int(self.dot_pos[1])),\n",
    "                           DOT_RADIUS, width=2)\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(RENDER_FPS)\n",
    "\n",
    "    def close(self):\n",
    "        if self.visualize and pygame is not None:\n",
    "            pygame.quit()\n",
    "        super().close()\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# TRAINING FUNCTION\n",
    "###############################################################################\n",
    "def train_model(total_timesteps=500_000, visualize=False):\n",
    "    \"\"\"\n",
    "    Train the PPO policy on our DemoArbitrationEnv with separate networks\n",
    "    for the actor and critic (no shared feature extractor).\n",
    "    Larger networks are used for both actor and critic to reduce overfitting.\n",
    "    \n",
    "    If visualize=True, a PyGame window will appear, updating in real time\n",
    "    (this slows training significantly).\n",
    "    \"\"\"\n",
    "    env = DemoArbitrationEnv(visualize=visualize)\n",
    "    env = DummyVecEnv([lambda: env])\n",
    "\n",
    "    metrics_callback = MetricsCallback()\n",
    "\n",
    "    callbacks = [metrics_callback]\n",
    "    if visualize:\n",
    "        render_callback = RenderCallback(render_freq=1)\n",
    "        callbacks.append(render_callback)\n",
    "\n",
    "    # Here we specify a custom net_arch for separate actor/critic:\n",
    "    #   dict(pi=[256, 256], vf=[256, 256])  \n",
    "    # and we disable shared feature extractor by default in MlpPolicy\n",
    "    # The result: no single \"shared\" feature extractor; \n",
    "    # the actor and critic each have their own MLP.\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=3e-4,\n",
    "        n_steps=1024,\n",
    "        batch_size=1024,\n",
    "        n_epochs=4,\n",
    "        gamma=0.99,\n",
    "        gae_lambda=0.95,\n",
    "        clip_range=0.2,\n",
    "        verbose=1,\n",
    "        tensorboard_log=\"./ppo_tensorboard/\",\n",
    "        policy_kwargs={\n",
    "            \"net_arch\": [\n",
    "                {\n",
    "                    \"pi\": [256, 256],\n",
    "                    \"vf\": [256, 256]\n",
    "                }\n",
    "            ],\n",
    "            \"activation_fn\": nn.ReLU,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    model.learn(\n",
    "        total_timesteps=total_timesteps,\n",
    "        callback=callbacks,\n",
    "        log_interval=1\n",
    "    )\n",
    "\n",
    "    # Save model\n",
    "    os.makedirs(\"trained_models\", exist_ok=True)\n",
    "    model_path = os.path.join(\"trained_models\", \"gamma_ppo_model\")\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}.zip\")\n",
    "\n",
    "    # Save metrics\n",
    "    metrics_callback.save_metrics(save_dir=\"training_metrics\")\n",
    "    print(\"Metrics saved to 'training_metrics/'\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# OPTIONAL: WATCH THE TRAINED MODEL\n",
    "###############################################################################\n",
    "def watch_trained_model(model_path=\"trained_models/gamma_ppo_model\"):\n",
    "    \"\"\"\n",
    "    Load a trained PPO model and watch it interact in a rendered environment.\n",
    "    \"\"\"\n",
    "    model = PPO.load(model_path)\n",
    "\n",
    "    env = DemoArbitrationEnv(visualize=True)\n",
    "    obs, _ = env.reset()\n",
    "    done, truncated = False, False\n",
    "\n",
    "    while not (done or truncated):\n",
    "        action, _states = model.predict(obs, deterministic=True)\n",
    "        obs, reward, done, truncated, info = env.step(action)\n",
    "        env.render()\n",
    "\n",
    "    env.close()\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# MAIN (EXAMPLE)\n",
    "###############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    # Train without visualization for speed\n",
    "    train_model(total_timesteps=100_000, visualize=False)\n",
    "\n",
    "    # Optionally watch the trained agent\n",
    "    # watch_trained_model(\"trained_models/gamma_ppo_model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
