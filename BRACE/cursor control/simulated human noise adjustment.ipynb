{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09efec7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# noise_analysis.py\n",
    "# ---------------------------------------------------------------------\n",
    "#  Quantifies trajectory‑noise of simulated agents from RGB screenshots\n",
    "# ---------------------------------------------------------------------\n",
    "# Copyright 2025  (MIT)\n",
    "# ---------------------------------------------------------------------\n",
    "from __future__ import annotations\n",
    "\n",
    "import argparse\n",
    "import hashlib\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from tqdm.auto import tqdm  # progress bar\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# LOGGING\n",
    "# ---------------------------------------------------------------------\n",
    "logging.basicConfig(\n",
    "    format=\"%(levelname)s | %(asctime)s | %(message)s\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# COLOUR / TRAJECTORY UTILITIES\n",
    "# ---------------------------------------------------------------------\n",
    "def dominant_colours(bgr_img: np.ndarray, k: int = 4) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    K‑means in RGB space, ignoring very dark pixels.\n",
    "    Returns k×3 uint8 matrix (BGR order as in OpenCV).\n",
    "    \"\"\"\n",
    "    flat = bgr_img.reshape(-1, 3)\n",
    "    flat = flat[(flat > 20).any(axis=1)]\n",
    "    if len(flat) < k:                       # fallback\n",
    "        return np.array([[255, 255, 255]], dtype=np.uint8)\n",
    "    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "    km.fit(flat)\n",
    "    return km.cluster_centers_.astype(np.uint8)\n",
    "\n",
    "\n",
    "def mask_for_colour(hsv: np.ndarray, colour_bgr: np.ndarray,\n",
    "                    tol: int = 30) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Build an HSV range mask centred on `colour_bgr`.\n",
    "    \"\"\"\n",
    "    colour_hsv = cv2.cvtColor(colour_bgr.reshape(1, 1, 3), cv2.COLOR_BGR2HSV)[0, 0]\n",
    "    lower = np.maximum(colour_hsv - tol, 0)\n",
    "    upper = np.minimum(colour_hsv + tol, 255)\n",
    "    return cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "\n",
    "def contour_points(mask: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Returns all contour pixel coordinates (N×2: x,y).\n",
    "    \"\"\"\n",
    "    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    pts: List[Tuple[int, int]] = []\n",
    "    for c in cnts:\n",
    "        pts.extend(p[0] for p in c)\n",
    "    return np.asarray(pts, dtype=np.int32) if pts else np.empty((0, 2), dtype=np.int32)\n",
    "\n",
    "\n",
    "def poly_noise(points: np.ndarray,\n",
    "               degree: int = 3) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Fit Y = f(X) polynomial (least‑squares) and return mean/std of the\n",
    "    *signed* residuals (noise levels).\n",
    "    \"\"\"\n",
    "    if len(points) < degree + 1:\n",
    "        return math.nan, math.nan\n",
    "\n",
    "    points = points[np.argsort(points[:, 0])]\n",
    "    x, y = points[:, 0:1], points[:, 1]\n",
    "    # remove duplicate X\n",
    "    uniq, idx = np.unique(x, return_index=True)\n",
    "    x, y = uniq.reshape(-1, 1), y[idx]\n",
    "\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    X_poly = poly.fit_transform(x)\n",
    "    model = LinearRegression().fit(X_poly, y)\n",
    "    y_pred = model.predict(X_poly)\n",
    "    res = y - y_pred\n",
    "    return float(res.mean()), float(res.std())\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# IMAGE‑LEVEL PIPELINE\n",
    "# ---------------------------------------------------------------------\n",
    "def analyse_image(path: Path,\n",
    "                  k: int,\n",
    "                  poly_deg: int) -> Dict[str, float] | None:\n",
    "    \"\"\"\n",
    "    Returns anonymised noise statistics or None if nothing detected.\n",
    "    \"\"\"\n",
    "    img = cv2.imread(str(path))\n",
    "    if img is None:\n",
    "        logging.warning(\"Cannot read %s\", path.name)\n",
    "        return None\n",
    "\n",
    "    colours = dominant_colours(img, k)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    noises = []\n",
    "\n",
    "    for c in colours:\n",
    "        pts = contour_points(mask_for_colour(hsv, c))\n",
    "        if len(pts):\n",
    "            mu, sd = poly_noise(pts, poly_deg)\n",
    "            if not math.isnan(mu):\n",
    "                noises.append((mu, sd))\n",
    "\n",
    "    if not noises:\n",
    "        return None\n",
    "\n",
    "    mus, sds = zip(*noises)\n",
    "    # histogram of residuals aggregated across colours\n",
    "    hist, edges = np.histogram(np.array(mus), bins=20, density=True)\n",
    "\n",
    "    return {\n",
    "        \"mean_noise\": float(np.mean(mus)),\n",
    "        \"std_noise\": float(np.mean(sds)),\n",
    "        \"hist\": hist.tolist(),\n",
    "        \"bins\": edges.tolist(),\n",
    "    }\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# FILENAME → SHA‑1 DIGEST  (anonymise)\n",
    "# ---------------------------------------------------------------------\n",
    "def anon_key(p: Path) -> str:\n",
    "    return hashlib.sha1(p.name.encode()).hexdigest()[:10]   # short hash\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# FOLDER‑LEVEL DRIVER\n",
    "# ---------------------------------------------------------------------\n",
    "def process_folder(folder: Path,\n",
    "                   k: int = 4,\n",
    "                   poly: int = 3,\n",
    "                   jobs: int = 1) -> Dict[str, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    Traverse folder, analyse each image, return dict keyed by anon hash.\n",
    "    \"\"\"\n",
    "    images = [p for p in folder.iterdir() if p.suffix.lower() in {\".png\", \".jpg\", \".jpeg\"}]\n",
    "    results: Dict[str, Dict[str, float]] = {}\n",
    "\n",
    "    def _task(p: Path):\n",
    "        return p, analyse_image(p, k, poly)\n",
    "\n",
    "    iterator = images if jobs == 1 else ProcessPoolExecutor(max_workers=jobs).map(_task, images)\n",
    "    for p, noise in tqdm(iterator, total=len(images), desc=\"analysing\"):\n",
    "        if noise:\n",
    "            results[anon_key(p)] = noise\n",
    "    return results\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# CLI\n",
    "# ---------------------------------------------------------------------\n",
    "def parse_args() -> argparse.Namespace:\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--input\", type=Path, required=True, help=\"folder with .png/.jpg\")\n",
    "    ap.add_argument(\"--out\",   type=Path, default=\"noise_profile.json\")\n",
    "    ap.add_argument(\"--k\",     type=int,  default=4, help=\"#dominant colours\")\n",
    "    ap.add_argument(\"--poly\",  type=int,  default=3, help=\"polynomial degree\")\n",
    "    ap.add_argument(\"--jobs\",  type=int,  default=1, help=\"parallel workers\")\n",
    "    return ap.parse_args()\n",
    "\n",
    "\n",
    "def main():\n",
    "    args = parse_args()\n",
    "    if not args.input.is_dir():\n",
    "        raise SystemExit(f\"Input folder {args.input} does not exist\")\n",
    "\n",
    "    noise_dict = process_folder(args.input, args.k, args.poly, args.jobs)\n",
    "    with open(args.out, \"w\") as f:\n",
    "        json.dump(noise_dict, f, indent=2)\n",
    "    logging.info(\"Wrote %d entries → %s\", len(noise_dict), args.out.resolve())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
