{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b463aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Train a Bayesian goal‑inference module à la BRACE.\n",
    "Requires:  numpy, torch  (≈ 50 lines of PyTorch total).\n",
    "\"\"\"\n",
    "\n",
    "import json, glob, math, numpy as np, torch\n",
    "from torch import nn, optim\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------\n",
    "#  Helper geometry functions\n",
    "# ----------------------------\n",
    "def unit(v):\n",
    "    n = np.linalg.norm(v)\n",
    "    return v / (n + 1e-9)\n",
    "\n",
    "def angle_between(a, b):\n",
    "    a_u, b_u = unit(a), unit(b)\n",
    "    dot = np.clip((a_u * b_u).sum(), -1.0, 1.0)\n",
    "    return np.arccos(dot)\n",
    "\n",
    "# ----------------------------\n",
    "#  Bayesian filter module\n",
    "# ----------------------------\n",
    "class BayesianGoalInference(nn.Module):\n",
    "    def __init__(self, n_goals, device='cpu'):\n",
    "        super().__init__()\n",
    "        # raw learnable parameters (positive by softplus)\n",
    "        self.raw_beta   = nn.Parameter(torch.tensor(2.0))\n",
    "        self.raw_wth    = nn.Parameter(torch.tensor(0.8))\n",
    "        self.raw_wdist  = nn.Parameter(torch.tensor(0.2))\n",
    "        self.n_goals    = n_goals\n",
    "        self.device     = device\n",
    "\n",
    "    # convenient positive transforms\n",
    "    def beta(self):   return torch.nn.functional.softplus(self.raw_beta)\n",
    "    def wth(self):    return torch.nn.functional.softplus(self.raw_wth)\n",
    "    def wdist(self):  return torch.nn.functional.softplus(self.raw_wdist)\n",
    "\n",
    "    def step_likelihood(self, hx, hy, x, y, goals):\n",
    "        \"\"\"\n",
    "        hx,hy : human input vector  (batch × 2)\n",
    "        x,y   : current cursor pos   (batch × 2)\n",
    "        goals : tensor (n_goals × 2)\n",
    "        returns: likelihood  (batch × n_goals)\n",
    "        \"\"\"\n",
    "        H = torch.stack([hx, hy], dim=-1)                      # B×2\n",
    "        P = torch.stack([x,  y ], dim=-1)                      # B×2\n",
    "        G = goals.to(self.device)                              # n×2\n",
    "        vec_to_g   = G[None,:,:] - P[:,None,:]                 # B×n×2\n",
    "        opt_dir    = vec_to_g / (vec_to_g.norm(dim=-1, keepdim=True)+1e-8)\n",
    "        h_dir      = H / (H.norm(dim=-1, keepdim=True)+1e-8)\n",
    "        ang_dev    = torch.arccos(torch.clamp((h_dir[:,None,:]*opt_dir).sum(-1),\n",
    "                                              -1.0, 1.0))      # B×n\n",
    "        dist_dev   = (H.norm(dim=-1, keepdim=True)+1e-8) / \\\n",
    "                     (opt_dir.norm(dim=-1)+1e-8) - 1.0         # B×n\n",
    "        cost = self.wth()*ang_dev.abs() + self.wdist()*dist_dev.abs()\n",
    "        ll   = (-self.beta()*cost).exp()                       # likelihood\n",
    "        return ll\n",
    "\n",
    "# ----------------------------\n",
    "#  Training loop\n",
    "# ----------------------------\n",
    "def load_dataset(folder):\n",
    "    \"\"\"Returns list of trajectories; each is (T, 6): x,y,hx,hy,goal_id\"\"\"\n",
    "    trajs = []\n",
    "    for path in glob.glob(str(Path(folder)/\"*.json\")):\n",
    "        data = json.load(open(path))\n",
    "        traj = [(d[\"x\"], d[\"y\"], d[\"hx\"], d[\"hy\"], d[\"goal_id\"]) for d in data]\n",
    "        trajs.append(np.array(traj, dtype=np.float32))\n",
    "    return trajs\n",
    "\n",
    "def train(folder, goal_positions, epochs=20, lr=5e-3, device='cpu'):\n",
    "    trajs = load_dataset(folder)\n",
    "    n_goals = len(goal_positions)\n",
    "    goals_t = torch.tensor(goal_positions, dtype=torch.float32)\n",
    "    model   = BayesianGoalInference(n_goals, device).to(device)\n",
    "    opt     = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        total_nll = 0.0\n",
    "        for traj in trajs:\n",
    "            opt.zero_grad()\n",
    "            # uniform prior\n",
    "            beliefs = torch.ones(n_goals, device=device)/n_goals\n",
    "            nll = 0.0\n",
    "            for step in traj:\n",
    "                x,y,hx,hy,goal = step\n",
    "                x = torch.tensor([x], device=device)\n",
    "                y = torch.tensor([y], device=device)\n",
    "                hx= torch.tensor([hx],device=device)\n",
    "                hy= torch.tensor([hy],device=device)\n",
    "                ll = model.step_likelihood(hx,hy,x,y, goals_t) # 1×n\n",
    "                beliefs = beliefs*ll.squeeze(0)\n",
    "                beliefs = beliefs / beliefs.sum()              # normalise\n",
    "                nll += -torch.log(beliefs[goal]+1e-9)          # −log p(true goal)\n",
    "            nll.backward()\n",
    "            opt.step()\n",
    "            total_nll += nll.item()\n",
    "        print(f\"epoch {ep:02d}  mean NLL per traj = {total_nll/len(trajs):.3f}\")\n",
    "    torch.save(model.state_dict(), \"bayes_goal_inference.pt\")\n",
    "    print(\"✓ model saved to bayes_goal_inference.pt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example goal positions (replace with your real task goals)\n",
    "    GOALS = [(200,200),(600,150),(350,500),(800,400)]\n",
    "    train(folder=\"demo_dataset\", goal_positions=GOALS)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
