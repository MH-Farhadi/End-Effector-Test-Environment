{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "class CursorControlEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A minimal environment for 2D cursor control with multiple goals and obstacles.\n",
    "    The agent controls the cursor by outputting a 2D action (dx, dy),\n",
    "    scaled by max_speed. The environment checks collisions, distance to goal,\n",
    "    and ends when the final goal is reached (or on collision).\n",
    "    \"\"\"\n",
    "    def __init__(self, width=1200, height=800, num_goals=3, enable_obstacles=True):\n",
    "        super(CursorControlEnv, self).__init__()\n",
    "\n",
    "        # Environment parameters\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_goals = num_goals\n",
    "        self.enable_obstacles = enable_obstacles\n",
    "\n",
    "        # Movement settings\n",
    "        self.max_speed = 3.0\n",
    "        self.dot_radius = 30.0\n",
    "        self.target_radius = 10.0\n",
    "        self.goal_detection_radius = self.dot_radius + self.target_radius\n",
    "        self.obstacle_radius = 20.0\n",
    "        self.collision_buffer = 5.0\n",
    "\n",
    "        # Action space: 2D continuous, each in [-1, 1]\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([-1.0, -1.0], dtype=np.float32),\n",
    "            high=np.array([ 1.0,  1.0], dtype=np.float32),\n",
    "            shape=(2,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Observation space (example):\n",
    "        #   [dot_x, dot_y, current_target_x, current_target_y]\n",
    "        # If you want to encode obstacle info or other goals, you can enlarge this.\n",
    "        high = np.array([self.width, self.height, self.width, self.height], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.zeros_like(high, dtype=np.float32),\n",
    "            high=high,\n",
    "            shape=(4,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # Internal state\n",
    "        self.dot_pos = None\n",
    "        self.targets = []\n",
    "        self.current_target_idx = None\n",
    "        self.obstacles = []\n",
    "        self.done = False\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Resets the environment state:\n",
    "          - Dot position = center of the window\n",
    "          - Generate random goals\n",
    "          - (Optionally) generate random obstacles\n",
    "        Returns the initial observation.\n",
    "        \"\"\"\n",
    "        self.dot_pos = np.array([self.width / 2, self.height / 2], dtype=np.float32)\n",
    "\n",
    "        # Generate goals\n",
    "        self.targets = []\n",
    "        for _ in range(self.num_goals):\n",
    "            gx = random.randint(0, self.width)\n",
    "            gy = random.randint(0, self.height)\n",
    "            self.targets.append(np.array([gx, gy], dtype=np.float32))\n",
    "\n",
    "        self.current_target_idx = 0\n",
    "\n",
    "        # Generate obstacles\n",
    "        self.obstacles = []\n",
    "        if self.enable_obstacles:\n",
    "            # Example: spawn 3 random obstacles\n",
    "            for _ in range(3):\n",
    "                ox = random.randint(int(self.obstacle_radius), int(self.width - self.obstacle_radius))\n",
    "                oy = random.randint(int(self.obstacle_radius), int(self.height - self.obstacle_radius))\n",
    "                self.obstacles.append(np.array([ox, oy], dtype=np.float32))\n",
    "\n",
    "        self.done = False\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Steps the environment forward by 1 timestep using the agent's action (dx, dy in [-1,1]).\n",
    "        1) Convert [-1,1] range to actual movement in [-max_speed, max_speed].\n",
    "        2) Update dot position, check collision, check if goal reached.\n",
    "        3) Return observation, reward, done, info.\n",
    "        \"\"\"\n",
    "        if self.done:\n",
    "            # If somehow step() called after done, just return something\n",
    "            return self._get_obs(), 0.0, True, {}\n",
    "\n",
    "        # Scale action to [-max_speed, max_speed]\n",
    "        dx = float(action[0]) * self.max_speed\n",
    "        dy = float(action[1]) * self.max_speed\n",
    "\n",
    "        # Proposed new position\n",
    "        new_x = self.dot_pos[0] + dx\n",
    "        new_y = self.dot_pos[1] + dy\n",
    "\n",
    "        # Clamp to environment bounds\n",
    "        new_x = np.clip(new_x, 0, self.width)\n",
    "        new_y = np.clip(new_y, 0, self.height)\n",
    "\n",
    "        # Check if the movement would collide with an obstacle\n",
    "        # For simplicity, we just check final position for overlap\n",
    "        if self.enable_obstacles:\n",
    "            if self._check_collision(self.dot_pos, [new_x, new_y]):\n",
    "                # If collision, give negative reward and end episode\n",
    "                reward = -10.0\n",
    "                self.done = True\n",
    "                return self._get_obs(), reward, self.done, {}\n",
    "\n",
    "        # Apply the movement\n",
    "        self.dot_pos[0] = new_x\n",
    "        self.dot_pos[1] = new_y\n",
    "\n",
    "        # Check goal progress\n",
    "        dist_to_goal = self._distance(self.dot_pos, self.current_goal)\n",
    "        done = False\n",
    "        reward = 0.0\n",
    "        # Reward shaping: negative for distance\n",
    "        # (this helps the agent learn that smaller distance is better)\n",
    "        reward -= dist_to_goal * 0.001\n",
    "\n",
    "        # Check if we reached the goal\n",
    "        if dist_to_goal <= self.goal_detection_radius:\n",
    "            reward += 10.0  # reward for reaching a goal\n",
    "            self.current_target_idx += 1\n",
    "            if self.current_target_idx >= self.num_goals:\n",
    "                done = True\n",
    "                self.done = True\n",
    "            else:\n",
    "                # Move on to next goal\n",
    "                pass\n",
    "\n",
    "        self.done = done\n",
    "        return self._get_obs(), reward, self.done, {}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        \"\"\"\n",
    "        (Optional) Render method if you want to visualize during training.\n",
    "        Here, weâ€™ll just print basic info. For a Pygame-based rendering, you'd\n",
    "        replicate some of your earlier drawing logic.\n",
    "        \"\"\"\n",
    "        print(f\"Dot: {self.dot_pos}, Current Goal: {self.current_goal}, Obstacles: {len(self.obstacles)}\")\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"\n",
    "        Return the current environment observation:\n",
    "          [dot_x, dot_y, current_goal_x, current_goal_y]\n",
    "        \"\"\"\n",
    "        return np.array([\n",
    "            self.dot_pos[0],\n",
    "            self.dot_pos[1],\n",
    "            self.current_goal[0],\n",
    "            self.current_goal[1]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    @property\n",
    "    def current_goal(self):\n",
    "        return self.targets[self.current_target_idx]\n",
    "\n",
    "    def _distance(self, pos1, pos2):\n",
    "        return math.hypot(pos1[0] - pos2[0], pos1[1] - pos2[1])\n",
    "\n",
    "    def _line_circle_intersection(self, start, end, center, radius):\n",
    "        \"\"\"\n",
    "        Checks if the line (start->end) intersects (or comes within radius) of center.\n",
    "        This logic is adapted from your original code snippet.\n",
    "        \"\"\"\n",
    "        dx = end[0] - start[0]\n",
    "        dy = end[1] - start[1]\n",
    "        cx = center[0] - start[0]\n",
    "        cy = center[1] - start[1]\n",
    "        l2 = dx*dx + dy*dy\n",
    "        if l2 == 0:\n",
    "            # start and end are the same\n",
    "            return self._distance(start, center) <= radius\n",
    "        t = max(0, min(1, (cx*dx + cy*dy) / l2))\n",
    "        proj_x = start[0] + t * dx\n",
    "        proj_y = start[1] + t * dy\n",
    "        return (self._distance((proj_x, proj_y), center) <= radius)\n",
    "\n",
    "    def _check_collision(self, old_pos, new_pos):\n",
    "        \"\"\"\n",
    "        Check if moving from old_pos to new_pos intersects any obstacle circle.\n",
    "        \"\"\"\n",
    "        for obs in self.obstacles:\n",
    "            # Expand radius by collision_buffer\n",
    "            if self._line_circle_intersection(old_pos, new_pos, obs, self.obstacle_radius + self.collision_buffer):\n",
    "                return True\n",
    "        return False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
