{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgym\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spaces\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PPO\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyVecEnv\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 1) HumanLikeAgent replaced by \"manual\" input from keyboard in the enjoy phase.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#    If you still want to simulate a \"human\" automatically, re-introduce that code.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\stable_baselines3\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ma2c\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m A2C\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_system_info\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mddpg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDPG\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\stable_baselines3\\a2c\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ma2c\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ma2c\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m A2C\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ma2c\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CnnPolicy, MlpPolicy, MultiInputPolicy\n\u001b[0;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCnnPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA2C\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\stable_baselines3\\a2c\\a2c.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgymnasium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spaces\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m functional \u001b[38;5;28;01mas\u001b[39;00m F\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuffers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RolloutBuffer\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mon_policy_algorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OnPolicyAlgorithm\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ActorCriticCnnPolicy, ActorCriticPolicy, BasePolicy, MultiInputActorCriticPolicy\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:16\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_action_dim, get_obs_shape\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtype_aliases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     DictReplayBufferSamples,\n\u001b[0;32m     12\u001b[0m     DictRolloutBufferSamples,\n\u001b[0;32m     13\u001b[0m     ReplayBufferSamples,\n\u001b[0;32m     14\u001b[0m     RolloutBufferSamples,\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_device\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvec_env\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VecNormalize\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Check memory used by replay buffer when possible\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\stable_baselines3\\common\\utils.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Check if tensorboard is available for pytorch\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 20\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     SummaryWriter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[misc, assignment]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\tensorboard\\__init__.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m Version\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tensorboard\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileWriter, SummaryWriter  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecord_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordWriter\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\tensorboard\\writer.py:12\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfigure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Figure\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m event_pb2\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Event, SessionLog\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector_config_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProjectorConfig\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\proto\\event_pb2.py:17\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_summary__pb2\n\u001b[0;32m     20\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     21\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard/compat/proto/event.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ,\n\u001b[0;32m     27\u001b[0m   dependencies\u001b[38;5;241m=\u001b[39m[tensorboard_dot_compat_dot_proto_dot_summary__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR,])\n\u001b[0;32m     29\u001b[0m _WORKERHEALTH \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mEnumDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWorkerHealth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard.WorkerHealth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1319\u001b[39m,\n\u001b[0;32m     56\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\proto\\summary_pb2.py:17\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_tensor__pb2\n\u001b[0;32m     20\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     21\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard/compat/proto/summary.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ,\n\u001b[0;32m     27\u001b[0m   dependencies\u001b[38;5;241m=\u001b[39m[tensorboard_dot_compat_dot_proto_dot_tensor__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR,])\n\u001b[0;32m     29\u001b[0m _DATACLASS \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mEnumDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataClass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard.DataClass\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1228\u001b[39m,\n\u001b[0;32m     56\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\proto\\tensor_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resource_handle_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_resource__handle__pb2\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_types__pb2\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\proto\\resource_handle_pb2.py:16\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_shape_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m types_pb2 \u001b[38;5;28;01mas\u001b[39;00m tensorboard_dot_compat_dot_proto_dot_types__pb2\n\u001b[0;32m     20\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     21\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard/compat/proto/resource_handle.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     22\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m   ,\n\u001b[0;32m     27\u001b[0m   dependencies\u001b[38;5;241m=\u001b[39m[tensorboard_dot_compat_dot_proto_dot_tensor__shape__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR,tensorboard_dot_compat_dot_proto_dot_types__pb2\u001b[38;5;241m.\u001b[39mDESCRIPTOR,])\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\proto\\tensor_shape_pb2.py:36\u001b[0m\n\u001b[0;32m     13\u001b[0m _sym_db \u001b[38;5;241m=\u001b[39m _symbol_database\u001b[38;5;241m.\u001b[39mDefault()\n\u001b[0;32m     18\u001b[0m DESCRIPTOR \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mFileDescriptor(\n\u001b[0;32m     19\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard/compat/proto/tensor_shape.proto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     20\u001b[0m   package\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m   serialized_pb\u001b[38;5;241m=\u001b[39m_b(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m+tensorboard/compat/proto/tensor_shape.proto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x10\u001b[39;00m\u001b[38;5;124mTensorShapeProto\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x64\u001b[39;00m\u001b[38;5;124mim\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x0b\u001b[39;00m\u001b[38;5;130;01m\\x32\u001b[39;00m\u001b[38;5;124m!.tensorboard.TensorShapeProto.Dim\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x14\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;124munknown_rank\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x08\u001b[39;00m\u001b[38;5;130;01m\\x1a\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x44\u001b[39;00m\u001b[38;5;124mim\u001b[39m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[38;5;124msize\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\x03\u001b[39;00m\u001b[38;5;130;01m\\x12\u001b[39;00m\u001b[38;5;130;01m\\x0c\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x04\u001b[39;00m\u001b[38;5;124mname\u001b[39m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;130;01m\\x02\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mB\u001b[39m\u001b[38;5;130;01m\\x87\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\x18\u001b[39;00m\u001b[38;5;124morg.tensorflow.frameworkB\u001b[39m\u001b[38;5;130;01m\\x11\u001b[39;00m\u001b[38;5;124mTensorShapeProtosP\u001b[39m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;124mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001b[39m\u001b[38;5;130;01m\\xf8\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x01\u001b[39;00m\u001b[38;5;130;01m\\x62\u001b[39;00m\u001b[38;5;130;01m\\x06\u001b[39;00m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     29\u001b[0m _TENSORSHAPEPROTO_DIM \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     30\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDim\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard.TensorShapeProto.Dim\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     32\u001b[0m   filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     33\u001b[0m   file\u001b[38;5;241m=\u001b[39mDESCRIPTOR,\n\u001b[0;32m     34\u001b[0m   containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     35\u001b[0m   fields\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m---> 36\u001b[0m     \u001b[43m_descriptor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFieldDescriptor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtensorboard.TensorShapeProto.Dim.size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcpp_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhas_default_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessage_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menum_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontaining_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43mis_extension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mserialized_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDESCRIPTOR\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     43\u001b[0m     _descriptor\u001b[38;5;241m.\u001b[39mFieldDescriptor(\n\u001b[0;32m     44\u001b[0m       name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m, full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard.TensorShapeProto.Dim.name\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     45\u001b[0m       number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, cpp_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     46\u001b[0m       has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, default_value\u001b[38;5;241m=\u001b[39m_b(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[0;32m     47\u001b[0m       message_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, enum_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, containing_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     48\u001b[0m       is_extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, extension_scope\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     49\u001b[0m       serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, file\u001b[38;5;241m=\u001b[39mDESCRIPTOR),\n\u001b[0;32m     50\u001b[0m   ],\n\u001b[0;32m     51\u001b[0m   extensions\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     52\u001b[0m   ],\n\u001b[0;32m     53\u001b[0m   nested_types\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     54\u001b[0m   enum_types\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     55\u001b[0m   ],\n\u001b[0;32m     56\u001b[0m   serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     57\u001b[0m   is_extendable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     58\u001b[0m   syntax\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproto3\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     59\u001b[0m   extension_ranges\u001b[38;5;241m=\u001b[39m[],\n\u001b[0;32m     60\u001b[0m   oneofs\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     61\u001b[0m   ],\n\u001b[0;32m     62\u001b[0m   serialized_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m,\n\u001b[0;32m     63\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m183\u001b[39m,\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     66\u001b[0m _TENSORSHAPEPROTO \u001b[38;5;241m=\u001b[39m _descriptor\u001b[38;5;241m.\u001b[39mDescriptor(\n\u001b[0;32m     67\u001b[0m   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorShapeProto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     68\u001b[0m   full_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensorboard.TensorShapeProto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m   serialized_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m183\u001b[39m,\n\u001b[0;32m    101\u001b[0m )\n\u001b[0;32m    103\u001b[0m _TENSORSHAPEPROTO_DIM\u001b[38;5;241m.\u001b[39mcontaining_type \u001b[38;5;241m=\u001b[39m _TENSORSHAPEPROTO\n",
      "File \u001b[1;32mc:\\Users\\mhfar\\anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py:553\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name, full_name, index, number, \u001b[38;5;28mtype\u001b[39m, cpp_type, label,\n\u001b[0;32m    548\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[0;32m    549\u001b[0m             is_extension, extension_scope, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    550\u001b[0m             serialized_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    551\u001b[0m             has_default_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, containing_oneof\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    552\u001b[0m             file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m--> 553\u001b[0m   \u001b[43m_message\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_CheckCalledFromGeneratedFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    554\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m is_extension:\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _message\u001b[38;5;241m.\u001b[39mdefault_pool\u001b[38;5;241m.\u001b[39mFindExtensionByName(full_name)\n",
      "\u001b[1;31mTypeError\u001b[0m: Descriptors cannot be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import pygame\n",
    "\n",
    "import gym\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "#\n",
    "# 1) HumanLikeAgent replaced by \"manual\" input from keyboard in the enjoy phase.\n",
    "#    If you still want to simulate a \"human\" automatically, re-introduce that code.\n",
    "#\n",
    "\n",
    "\n",
    "class CursorControlEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    A 2D environment with:\n",
    "      - Exactly ONE randomly chosen goal each episode\n",
    "      - Weighted sum of agent_action + manual/human_action\n",
    "      - Reward for staying close to the perfect path from start->goal (straight line).\n",
    "    No obstacles.\n",
    "\n",
    "    In \"training mode\", we simulate a random 'human' so the agent can learn a policy.\n",
    "    In \"manual mode\", we read keyboard input so you can see how the policy behaves with your input.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        width=800,\n",
    "        height=600,\n",
    "        gamma=0.5,              # weight for PPO agent's action in the sum\n",
    "        max_steps=500,\n",
    "        goal_distance_threshold=20.0,\n",
    "        render_mode=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.gamma = gamma\n",
    "        self.max_steps = max_steps\n",
    "        self.goal_distance_threshold = goal_distance_threshold\n",
    "\n",
    "        # Spaces\n",
    "        # PPO agent outputs a 2D action in [-1,1].\n",
    "        # We'll combine it with a \"human/manual\" action (also in [-1,1]) in step().\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([-1.0, -1.0], dtype=np.float32),\n",
    "            high=np.array([1.0,  1.0], dtype=np.float32),\n",
    "            shape=(2,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        # Observations: [dot_x, dot_y, goal_x, goal_y]\n",
    "        high = np.array([width, height, width, height], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.zeros_like(high, dtype=np.float32),\n",
    "            high=high,\n",
    "            shape=(4,),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "\n",
    "        # State\n",
    "        self.dot_pos = None\n",
    "        self.start_pos = None\n",
    "        self.goal_pos = None\n",
    "        self.current_step = 0\n",
    "        self.done_flag = False\n",
    "\n",
    "        self.max_speed = 3.0  # scale for final movement\n",
    "        self.dot_radius = 10.0\n",
    "\n",
    "        # Rendering\n",
    "        self.render_mode = render_mode\n",
    "        if self.render_mode:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.width, self.height))\n",
    "            pygame.display.set_caption(\"Cursor Control: Manual + Agent\")\n",
    "            self.clock = pygame.time.Clock()\n",
    "            self.font = pygame.font.SysFont(None, 24)\n",
    "\n",
    "        # For training mode, we simulate a random human action\n",
    "        # (If you want a better \"human\" model, adapt these.)\n",
    "        self.simulate_human_noise = 0.3\n",
    "\n",
    "    def reset(self):\n",
    "        self.done_flag = False\n",
    "        self.current_step = 0\n",
    "        self.dot_pos = np.array([self.width/2, self.height/2], dtype=np.float32)\n",
    "        self.start_pos = self.dot_pos.copy()\n",
    "\n",
    "        gx = random.uniform(0, self.width)\n",
    "        gy = random.uniform(0, self.height)\n",
    "        self.goal_pos = np.array([gx, gy], dtype=np.float32)\n",
    "\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, agent_action, manual_action=None):\n",
    "        \"\"\"\n",
    "        Step the environment:\n",
    "          agent_action: (dx, dy) from PPO in [-1,1].\n",
    "          manual_action: (dx, dy) from keyboard/human in [-1,1].\n",
    "                         If None, we simulate a random 'human' for training.\n",
    "\n",
    "        Weighted sum:\n",
    "          combined = gamma*(agent_action) + (1-gamma)*(manual_action)\n",
    "        Then scaled by self.max_speed, applied to self.dot_pos.\n",
    "\n",
    "        Reward = negative distance to the perfect line (start->goal),\n",
    "                 +10 if within threshold of the goal.\n",
    "        \"\"\"\n",
    "        if self.done_flag:\n",
    "            # If called after done, just return the current state\n",
    "            return self._get_obs(), 0.0, True, {}\n",
    "\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= self.max_steps:\n",
    "            self.done_flag = True\n",
    "            return self._get_obs(), 0.0, True, {}\n",
    "\n",
    "        # If no manual_action is provided, we assume \"training mode\"\n",
    "        if manual_action is None:\n",
    "            manual_action = self._simulate_random_human()\n",
    "\n",
    "        # Weighted sum\n",
    "        combined_x = self.gamma * agent_action[0] + (1 - self.gamma) * manual_action[0]\n",
    "        combined_y = self.gamma * agent_action[1] + (1 - self.gamma) * manual_action[1]\n",
    "\n",
    "        # Scale by max_speed\n",
    "        dx = float(combined_x) * self.max_speed\n",
    "        dy = float(combined_y) * self.max_speed\n",
    "\n",
    "        new_x = np.clip(self.dot_pos[0] + dx, 0, self.width)\n",
    "        new_y = np.clip(self.dot_pos[1] + dy, 0, self.height)\n",
    "        self.dot_pos = np.array([new_x, new_y], dtype=np.float32)\n",
    "\n",
    "        # Reward shaping\n",
    "        dist_line = self._distance_to_line(self.start_pos, self.goal_pos, self.dot_pos)\n",
    "        reward = -0.01 * dist_line\n",
    "\n",
    "        dist_to_goal = np.linalg.norm(self.dot_pos - self.goal_pos)\n",
    "        if dist_to_goal < self.goal_distance_threshold:\n",
    "            reward += 10.0\n",
    "            self.done_flag = True\n",
    "\n",
    "        return self._get_obs(), reward, self.done_flag, {}\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        if not self.render_mode:\n",
    "            return\n",
    "        # Standard Pygame event check so the window doesn't freeze\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                pygame.quit()\n",
    "                sys.exit()\n",
    "\n",
    "        self.screen.fill((255, 255, 255))\n",
    "\n",
    "        # Perfect path line\n",
    "        pygame.draw.line(\n",
    "            self.screen, (200, 200, 200),\n",
    "            (int(self.start_pos[0]), int(self.start_pos[1])),\n",
    "            (int(self.goal_pos[0]), int(self.goal_pos[1])),\n",
    "            2\n",
    "        )\n",
    "        # Goal\n",
    "        pygame.draw.circle(\n",
    "            self.screen,\n",
    "            (255, 0, 0),\n",
    "            (int(self.goal_pos[0]), int(self.goal_pos[1])),\n",
    "            8\n",
    "        )\n",
    "        # Dot\n",
    "        pygame.draw.circle(\n",
    "            self.screen,\n",
    "            (0, 0, 255),\n",
    "            (int(self.dot_pos[0]), int(self.dot_pos[1])),\n",
    "            int(self.dot_radius)\n",
    "        )\n",
    "\n",
    "        text = self.font.render(f\"Step: {self.current_step}\", True, (0,0,0))\n",
    "        self.screen.blit(text, (10, 10))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(60)\n",
    "\n",
    "    def close(self):\n",
    "        if self.render_mode:\n",
    "            pygame.quit()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.array([\n",
    "            self.dot_pos[0],\n",
    "            self.dot_pos[1],\n",
    "            self.goal_pos[0],\n",
    "            self.goal_pos[1]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    def _simulate_random_human(self):\n",
    "        \"\"\"\n",
    "        For training: a simple random direction to emulate a 'confused' or random user.\n",
    "        Could be replaced by a more realistic noisy action toward the goal.\n",
    "        \"\"\"\n",
    "        dx = np.random.uniform(-1, 1)\n",
    "        dy = np.random.uniform(-1, 1)\n",
    "        # Optional mild normalization\n",
    "        mag = math.hypot(dx, dy)\n",
    "        if mag > 1e-6:\n",
    "            dx /= mag\n",
    "            dy /= mag\n",
    "        # Add small noise\n",
    "        dx += np.random.normal(0, self.simulate_human_noise)\n",
    "        dy += np.random.normal(0, self.simulate_human_noise)\n",
    "        # Re-normalize if we want to keep it in [-1,1]\n",
    "        mag = math.hypot(dx, dy)\n",
    "        if mag > 1e-6:\n",
    "            dx /= mag\n",
    "            dy /= mag\n",
    "        return np.array([dx, dy], dtype=np.float32)\n",
    "\n",
    "    def _distance_to_line(self, start, end, point):\n",
    "        line_len = np.linalg.norm(end - start)\n",
    "        if line_len < 1e-9:\n",
    "            return np.linalg.norm(point - start)\n",
    "        t = np.dot(point - start, end - start) / (line_len**2)\n",
    "        t = max(0.0, min(1.0, t))\n",
    "        proj = start + t * (end - start)\n",
    "        return np.linalg.norm(point - proj)\n",
    "\n",
    "\n",
    "def run_manual_control(model):\n",
    "    \"\"\"\n",
    "    Let you manually control the environment (via arrow keys).\n",
    "    The PPO model also outputs an action each step.\n",
    "    We do a weighted sum of (model_action, your_action).\n",
    "    This loop continues until you close the window.\n",
    "    \"\"\"\n",
    "    env = CursorControlEnv(render_mode=True)  # GUI\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0.0\n",
    "\n",
    "    print(\"\\nManual control + PPO running!\")\n",
    "    print(\"Use arrow keys to move. Window will remain open until you close it.\")\n",
    "\n",
    "    while True:  # We'll let you run multiple episodes in a row\n",
    "        # If episode is done, reset\n",
    "        if done:\n",
    "            print(f\"Episode finished. Total reward: {total_reward:.2f}\")\n",
    "            obs = env.reset()\n",
    "            done = False\n",
    "            total_reward = 0.0\n",
    "\n",
    "        # 1) Check for user input from pygame\n",
    "        #    We'll convert arrow keys to a [-1,1] action\n",
    "        #    e.g. left arrow => (-1, 0), right arrow => (+1, 0)\n",
    "        pygame.event.pump()  # to get current key states\n",
    "        keys = pygame.key.get_pressed()\n",
    "        user_dx = 0.0\n",
    "        user_dy = 0.0\n",
    "        if keys[pygame.K_LEFT]:\n",
    "            user_dx -= 1.0\n",
    "        if keys[pygame.K_RIGHT]:\n",
    "            user_dx += 1.0\n",
    "        if keys[pygame.K_UP]:\n",
    "            user_dy -= 1.0\n",
    "        if keys[pygame.K_DOWN]:\n",
    "            user_dy += 1.0\n",
    "\n",
    "        # If you want to exit, press ESC or close the window\n",
    "        if keys[pygame.K_ESCAPE]:\n",
    "            break\n",
    "\n",
    "        # Normalize if needed\n",
    "        mag = math.hypot(user_dx, user_dy)\n",
    "        if mag > 1e-6:\n",
    "            user_dx /= mag\n",
    "            user_dy /= mag\n",
    "\n",
    "        manual_action = np.array([user_dx, user_dy], dtype=np.float32)\n",
    "\n",
    "        # 2) Get the PPO model's action\n",
    "        model_action, _states = model.predict(obs, deterministic=True)\n",
    "\n",
    "        # 3) Step the environment with both\n",
    "        obs, reward, done, info = env.step(\n",
    "            agent_action=model_action,\n",
    "            manual_action=manual_action\n",
    "        )\n",
    "        total_reward += reward\n",
    "\n",
    "        # 4) Render\n",
    "        env.render()\n",
    "\n",
    "    env.close()\n",
    "    print(\"Closed manual control window. Exiting...\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    1) Train a PPO model in a headless environment (where 'human' is random).\n",
    "    2) Afterwards, let the user manually control the dot (arrow keys) combined\n",
    "       with the modelâ€™s action in real time.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) TRAINING (headless)\n",
    "    train_env = CursorControlEnv(render_mode=False)\n",
    "    vec_env = DummyVecEnv([lambda: train_env])\n",
    "    model = PPO(\n",
    "        \"MlpPolicy\",\n",
    "        vec_env,\n",
    "        verbose=1,\n",
    "        n_steps=1024,\n",
    "        batch_size=64,\n",
    "        learning_rate=3e-4,\n",
    "        gamma=0.99,\n",
    "        ent_coef=0.01\n",
    "    )\n",
    "\n",
    "    print(\"Training PPO for 100,000 steps (this may take a while)...\")\n",
    "    model.learn(total_timesteps=100_000)\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    # 2) MANUAL CONTROL DEMO\n",
    "    run_manual_control(model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
